input {
  file {
    path => "/usr/share/logstash/input_logs/*.txt"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    type => "mozilla-build"
    codec => "plain"
    mode => "read"
    exit_after_read => false
    file_completed_action => "log"
    file_completed_log_path => "/usr/share/logstash/processed_files.log"
  }
  
  beats {
    port => 5044
    host => "0.0.0.0"
  }
}

filter {
  # Grok patterns pour les logs Mozilla
  grok {
    break_on_match => false
    patterns_dir => ["/usr/share/logstash/patterns"]
    
    # Métadonnées de base
    match => { 
      "message" => [
        "builder: %{DATA:builder}",
        "slave: %{DATA:slave}",
        "starttime: %{NUMBER:start_timestamp}",
        "results: %{WORD:result_status}",
        "buildid: %{DATA:build_id}",
        "revision: %{DATA:revision}",
        "builduid: %{DATA:build_uid}"
      ]
    }
    tag_on_failure => []
  }
  
  # Extraction des étapes de build
  grok {
    match => { 
      "message" => "========= Started %{DATA:step_name}.*\(results: %{NUMBER:step_result}, elapsed: %{NUMBER:step_duration} secs\)"
    }
    tag_on_failure => []
  }
  
  # Extraction du temps d'exécution
  grok {
    match => { "message" => "elapsedTime=%{NUMBER:elapsed_time}" }
    tag_on_failure => []
  }
  
  # Extraction du code de sortie
  grok {
    match => { "message" => "program finished with exit code %{NUMBER:exit_code}" }
    tag_on_failure => []
  }
  
  # Extraction des suites de tests
  if "mochitest-suite" in [message] {
    grok {
      match => { "message" => "--mochitest-suite (%{DATA:test_suites_raw})" }
    }
    
    mutate {
      gsub => [ "test_suites_raw", ",", " " ]
      split => { "test_suites_raw" => " " }
      rename => { "test_suites_raw" => "test_suites" }
    }
  }
  
  # Détection des builds annulés
  if "Cancelled via self-serve" in [message] {
    grok {
      match => { "message" => "pressed by '%{EMAIL:cancelled_by}'" }
    }
    
    mutate {
      add_tag => [ "cancelled_build" ]
      add_field => { "cancellation_reason" => "self_serve" }
    }
  }
  
  # Conversion des types de données
  mutate {
    convert => {
      "step_duration" => "float"
      "elapsed_time" => "float"
      "exit_code" => "integer"
      "start_timestamp" => "float"
    }
    
    # Nettoyage des champs
    gsub => [
      "step_name", "interrupted", "interrompu",
      "step_name", "no change", "aucun_changement"
    ]
  }
  
  # Conversion du timestamp Unix
  if [start_timestamp] {
    date {
      match => [ "start_timestamp", "UNIX" ]
      target => "start_datetime"
    }
  }
  
  # Ajout de métadonnées
  mutate {
    add_field => {
      "processing_timestamp" => "%{@timestamp}"
      "log_source" => "mozilla_build"
    }
  }
  
  # Géolocalisation basique (si informations disponibles)
  if [slave] {
    grok {
      match => { "slave" => "t-%{WORD:region}-%{DATA}" }
      add_field => { "location" => "%{region}" }
    }
  }
}

output {
  # Sortie vers Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "mozilla-builds-%{+YYYY.MM.dd}"
    document_id => "%{build_id}-%{slave}"
    template => "/usr/share/logstash/pipeline/mozilla-template.json"
    template_name => "mozilla-builds"
  }
  
  # Sortie de debug
  stdout { 
    codec => rubydebug 
  }
  
  # Sauvegarde des erreurs
  if "_grokparsefailure" in [tags] {
    file {
      path => "/usr/share/logstash/failed_parses-%{+YYYY-MM-dd}.log"
    }
  }
}